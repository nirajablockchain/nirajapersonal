{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nirajablockchain/nirajapersonal/blob/main/Copy_of_Copy_of_Wav2Lip_quick_trial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSQFs_G8caeE"
      },
      "source": [
        "# Collab preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIVB0Xn1g6ih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "675d69ca-0c3f-4d87-effe-420443a021bb"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qciH4PsUazL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "107151a2-38b3-4c6c-bca3-98068869fc69"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ5taGmPcWV-"
      },
      "source": [
        "# Get the code and models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3LihClHbUd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c863120-dcd5-4d18-e343-70c053505858"
      },
      "source": [
        "!git clone https://github.com/Rudrabha/Wav2Lip.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Wav2Lip'...\n",
            "remote: Enumerating objects: 360, done.\u001b[K\n",
            "remote: Total 360 (delta 0), reused 0 (delta 0), pack-reused 360\u001b[K\n",
            "Receiving objects: 100% (360/360), 522.32 KiB | 4.21 MiB/s, done.\n",
            "Resolving deltas: 100% (198/198), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-19nzx8SamJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d522dab-1341-40bd-8a44-970d060a6bc6"
      },
      "source": [
        "!ls /content/gdrive/MyDrive/Wav2Lip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio.py\t\tface_detection\t     models\t    requirements.txt\n",
            "checkpoints\t\tfilelists\t     monatest1.mp4  results\n",
            "color_syncnet_train.py\thparams.py\t     monatest.jpg   temp\n",
            "download1.wav\t\thq_wav2lip_train.py  preprocess.py  wav2lip_train.py\n",
            "evaluation\t\tinference.py\t     README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjzMPy_Sb0AI"
      },
      "source": [
        "!cp -ri \"/content/gdrive/MyDrive/Wav2lip/wav2lip_gan.pth\" /content/Wav2Lip/checkpoints/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWTaOS3ncFt6"
      },
      "source": [
        "# Get the pre-requisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ooh28vw-Uvd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68d5206a-4275-4db2-edc6-d00f43698aed"
      },
      "source": [
        "!pip uninstall tensorflow tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.12.0\n",
            "Uninstalling tensorflow-2.12.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.9/dist-packages/tensorflow-2.12.0.dist-info/*\n",
            "    /usr/local/lib/python3.9/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? Y\n",
            "Y\n",
            "  Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49dCYlLdcK2D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "112e50f1-63fc-4273-a771-f5ed87d3e190"
      },
      "source": [
        "!cd Wav2Lip && pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting librosa==0.7.0\n",
            "  Downloading librosa-0.7.0.tar.gz (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy==1.17.1\n",
            "  Downloading numpy-1.17.1.zip (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: opencv-contrib-python>=4.2.0.34 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 3)) (4.7.0.72)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python==4.1.0.25 (from versions: 3.4.0.14, 3.4.10.37, 3.4.11.39, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.14.51, 3.4.14.53, 3.4.15.55, 3.4.16.57, 3.4.16.59, 3.4.17.61, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.42, 4.4.0.44, 4.4.0.46, 4.5.1.48, 4.5.2.52, 4.5.2.54, 4.5.3.56, 4.5.4.58, 4.5.4.60, 4.5.5.62, 4.5.5.64, 4.6.0.66, 4.7.0.68, 4.7.0.72)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv-python==4.1.0.25\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey_bN4M6X_95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab33517b-21e0-478d-b819-3d35c23f4609"
      },
      "source": [
        "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"Wav2Lip/face_detection/detection/sfd/s3fd.pth\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-10 13:27:22--  https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\n",
            "Resolving www.adrianbulat.com (www.adrianbulat.com)... 45.136.29.207\n",
            "Connecting to www.adrianbulat.com (www.adrianbulat.com)|45.136.29.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 89843225 (86M) [application/octet-stream]\n",
            "Saving to: ‘Wav2Lip/face_detection/detection/sfd/s3fd.pth’\n",
            "\n",
            "Wav2Lip/face_detect 100%[===================>]  85.68M  9.17MB/s    in 8.5s    \n",
            "\n",
            "2023-04-10 13:27:31 (10.1 MB/s) - ‘Wav2Lip/face_detection/detection/sfd/s3fd.pth’ saved [89843225/89843225]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdIQfY2Kswcb"
      },
      "source": [
        "# Now lets try!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoVGMtjRZfeR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4baf940b-c9aa-4989-b07a-c6cfe232f9de"
      },
      "source": [
        "!cp \"/content/gdrive/My Drive/Wav2Lip/redo.mp4\" \"/content/gdrive/My Drive/Wav2Lip/redo.wav\" sample_data/\n",
        "!ls sample_data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anscombe.json\t\t      mnist_test.csv\t     redo.mp4\n",
            "california_housing_test.csv   mnist_train_small.csv  redo.wav\n",
            "california_housing_train.csv  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/gdrive/My Drive/Wav2Lip/audio.py\" \"/content/Wav2Lip/audio.py\""
      ],
      "metadata": {
        "id": "15IiHyFgYnbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR5utmDMcSZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb01e46d-0cfe-4f46-8650-c4ec48e2ff47"
      },
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../sample_data/redo.mp4\" --audio \"../sample_data/redo.wav\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda for inference.\n",
            "Reading video frames...\n",
            "Number of frames available for inference: 2045\n",
            "(80, 1857)\n",
            "Length of mel chunks: 692\n",
            "  0% 0/6 [00:00<?, ?it/s]\n",
            "  0% 0/44 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 1/44 [00:23<16:36, 23.18s/it]\u001b[A\n",
            "  5% 2/44 [00:24<07:24, 10.58s/it]\u001b[A\n",
            "  7% 3/44 [00:26<04:26,  6.49s/it]\u001b[A\n",
            "  9% 4/44 [00:28<03:01,  4.55s/it]\u001b[A\n",
            " 11% 5/44 [00:29<02:15,  3.46s/it]\u001b[A\n",
            " 14% 6/44 [00:31<01:50,  2.91s/it]\u001b[A\n",
            " 16% 7/44 [00:33<01:35,  2.57s/it]\u001b[A\n",
            " 18% 8/44 [00:35<01:24,  2.34s/it]\u001b[A\n",
            " 20% 9/44 [00:36<01:13,  2.10s/it]\u001b[A\n",
            " 23% 10/44 [00:38<01:06,  1.97s/it]\u001b[A\n",
            " 25% 11/44 [00:40<01:01,  1.86s/it]\u001b[A\n",
            " 27% 12/44 [00:41<00:57,  1.79s/it]\u001b[A\n",
            " 30% 13/44 [00:43<00:55,  1.78s/it]\u001b[A\n",
            " 32% 14/44 [00:45<00:55,  1.85s/it]\u001b[A\n",
            " 34% 15/44 [00:47<00:58,  2.01s/it]\u001b[A\n",
            " 36% 16/44 [00:49<00:54,  1.96s/it]\u001b[A\n",
            " 39% 17/44 [00:51<00:50,  1.86s/it]\u001b[A\n",
            " 41% 18/44 [00:53<00:46,  1.80s/it]\u001b[A\n",
            " 43% 19/44 [00:54<00:43,  1.75s/it]\u001b[A\n",
            " 45% 20/44 [00:56<00:40,  1.69s/it]\u001b[A\n",
            " 48% 21/44 [00:57<00:38,  1.68s/it]\u001b[A\n",
            " 50% 22/44 [00:59<00:38,  1.74s/it]\u001b[A\n",
            " 52% 23/44 [01:01<00:37,  1.79s/it]\u001b[A\n",
            " 55% 24/44 [01:03<00:34,  1.74s/it]\u001b[A\n",
            " 57% 25/44 [01:04<00:32,  1.71s/it]\u001b[A\n",
            " 59% 26/44 [01:06<00:29,  1.66s/it]\u001b[A\n",
            " 61% 27/44 [01:07<00:27,  1.61s/it]\u001b[A\n",
            " 64% 28/44 [01:09<00:25,  1.57s/it]\u001b[A\n",
            " 66% 29/44 [01:10<00:23,  1.55s/it]\u001b[A\n",
            " 68% 30/44 [01:12<00:22,  1.60s/it]\u001b[A\n",
            " 70% 31/44 [01:14<00:22,  1.71s/it]\u001b[A\n",
            " 73% 32/44 [01:16<00:20,  1.68s/it]\u001b[A\n",
            " 75% 33/44 [01:17<00:18,  1.65s/it]\u001b[A\n",
            " 77% 34/44 [01:19<00:16,  1.63s/it]\u001b[A\n",
            " 80% 35/44 [01:20<00:14,  1.60s/it]\u001b[A\n",
            " 82% 36/44 [01:22<00:12,  1.58s/it]\u001b[A\n",
            " 84% 37/44 [01:24<00:11,  1.58s/it]\u001b[A\n",
            " 86% 38/44 [01:25<00:09,  1.57s/it]\u001b[A\n",
            " 89% 39/44 [01:27<00:08,  1.65s/it]\u001b[A\n",
            " 91% 40/44 [01:29<00:06,  1.70s/it]\u001b[A\n",
            " 93% 41/44 [01:30<00:05,  1.72s/it]\u001b[A\n",
            " 95% 42/44 [01:32<00:03,  1.72s/it]\u001b[A\n",
            " 98% 43/44 [01:34<00:01,  1.71s/it]\u001b[A\n",
            "100% 44/44 [01:39<00:00,  2.25s/it]\n",
            "Load checkpoint from: checkpoints/wav2lip_gan.pth\n",
            "Model loaded\n",
            "100% 6/6 [02:04<00:00, 20.76s/it]\n",
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
            "\u001b[0mInput #0, wav, from '../sample_data/redo.wav':\n",
            "  Duration: 00:00:23.21, bitrate: 768 kb/s\n",
            "    Stream #0:0: Audio: pcm_f32le ([3][0][0][0] / 0x0003), 24000 Hz, mono, flt, 768 kb/s\n",
            "Input #1, avi, from 'temp/result.avi':\n",
            "  Metadata:\n",
            "    encoder         : Lavf59.27.100\n",
            "  Duration: 00:00:23.07, start: 0.000000, bitrate: 6568 kb/s\n",
            "    Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 480x854 [SAR 1:1 DAR 240:427], 6570 kb/s, 30 fps, 30 tbr, 30 tbn, 30 tbc\n",
            "Stream mapping:\n",
            "  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
            "  Stream #0:0 -> #0:1 (pcm_f32le (native) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x559b49b0be80] \u001b[0m\u001b[0;33m-qscale is ignored, -crf is recommended.\n",
            "\u001b[0m\u001b[1;36m[libx264 @ 0x559b49b0be80] \u001b[0musing SAR=1/1\n",
            "\u001b[1;36m[libx264 @ 0x559b49b0be80] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x559b49b0be80] \u001b[0mprofile High, level 3.1\n",
            "\u001b[1;36m[libx264 @ 0x559b49b0be80] \u001b[0m264 - core 155 r2917 0a84d98 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to 'results/result_voice.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.29.100\n",
            "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p(progressive), 480x854 [SAR 1:1 DAR 240:427], q=-1--1, 30 fps, 15360 tbn, 30 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.54.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
            "    Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 24000 Hz, mono, fltp, 69 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.54.100 aac\n",
            "frame=  692 fps= 33 q=-1.0 Lsize=    4814kB time=00:00:23.21 bitrate=1699.1kbits/s speed= 1.1x    \n",
            "video:4598kB audio:197kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.397434%\n",
            "\u001b[1;36m[libx264 @ 0x559b49b0be80] \u001b[0mframe I:3     Avg QP:22.21  size: 49352\n",
            "\u001b[1;36m[libx264 @ 0x559b49b0be80] \u001b[0mframe P:247   Avg QP:24.53  size: 13770\n",
            "\u001b[1;36m[libx264 @ 0x559b49b0be80] \u001b[0mframe B:442   Avg QP:28.36  size:  2622\n",
            "\u001b[1;36m[libx264 @ 0x559b49b0be80] \u001b[0mconsecutive B-frames:  9.0% 15.9%  5.2% 69.9%\n",
            "\u001b[1;36m[libx264 @ 0x559b49b0be80] \u001b[0mmb I  I16..4:  9.8% 77.1% 13.1%\n",
            "\u001b[1;36m[libx264 @ 0x559b49b0be80] \u001b[0mmb P  I16..4:  2.5% 10.9%  1.4%  P16..4: 39.3% 19.6% 12.6%  0.0%  0.0%    skip:13.7%\n",
            "\u001b[1;36m[libx264 @ 0x559b49b0be80] \u001b[0mmb B  I16..4:  0.4%  1.7%  0.2%  B16..8: 37.7%  6.1%  1.1%  direct: 1.3%  skip:51.6%  L0:43.6% L1:39.3% BI:17.0%\n",
            "\u001b[1;36m[libx264 @ 0x559b49b0be80] \u001b[0m8x8 transform intra:73.8% inter:69.2%\n",
            "\u001b[1;36m[libx264 @ 0x559b49b0be80] \u001b[0mcoded y,uvDC,uvAC intra: 59.8% 77.8% 20.2% inter: 18.3% 19.2% 2.6%\n",
            "\u001b[1;36m[libx264 @ 0x559b49b0be80] \u001b[0mi16 v,h,dc,p: 32% 18% 25% 25%\n",
            "\u001b[1;36m[libx264 @ 0x559b49b0be80] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 26% 19% 26%  4%  5%  6%  5%  5%  5%\n",
            "\u001b[1;36m[libx264 @ 0x559b49b0be80] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 25% 19% 10%  5%  9%  9% 11%  6%  6%\n",
            "\u001b[1;36m[libx264 @ 0x559b49b0be80] \u001b[0mi8c dc,h,v,p: 45% 21% 26%  8%\n",
            "\u001b[1;36m[libx264 @ 0x559b49b0be80] \u001b[0mWeighted P-Frames: Y:9.3% UV:0.0%\n",
            "\u001b[1;36m[libx264 @ 0x559b49b0be80] \u001b[0mref P L0: 66.5% 15.5% 13.1%  4.5%  0.3%\n",
            "\u001b[1;36m[libx264 @ 0x559b49b0be80] \u001b[0mref B L0: 90.7%  7.9%  1.5%\n",
            "\u001b[1;36m[libx264 @ 0x559b49b0be80] \u001b[0mref B L1: 98.0%  2.0%\n",
            "\u001b[1;36m[libx264 @ 0x559b49b0be80] \u001b[0mkb/s:1632.84\n",
            "\u001b[1;36m[aac @ 0x559b49b00c40] \u001b[0mQavg: 125.645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNOAZvkszEOw"
      },
      "source": [
        "# use the \"files\" button on the left to download the result in the Wav2Lip/results/ folder."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7zgfrQqbKom"
      },
      "source": [
        "## **Variations to try**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f9A9VDVbZAG"
      },
      "source": [
        "1.   Use more padding to include the chin region"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45XW4SZAzIz5"
      },
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../sample_data/test.mp4\" --audio \"../sample_data/sdfnsdkgnjksdgv.wav\" --pads 0 20 0 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo-WnsxfbwTG"
      },
      "source": [
        "2.   Use resize_factor to reduce the video resolution, as there is a change you might get better results for lower resolution videos. Why? Because the model was trained on low resolution faces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw0xFtZ2bsx8"
      },
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../sample_data/input_vid.mp4\" --audio \"../sample_data/input_audio.wav\" --resize_factor 2"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}