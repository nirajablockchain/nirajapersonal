prev_progress = 0
def reward_function(params):
    '''
    Example of rewarding the agent to stay inside two borders
    and penalizing getting too close to the objects in front
    '''

    all_wheels_on_track = params['all_wheels_on_track']
    distance_from_center = params['distance_from_center']
    track_width = params['track_width']
    objects_distance = params['objects_distance']
    _, next_object_index = params['closest_objects']
    objects_left_of_center = params['objects_left_of_center']
    is_left_of_center = params['is_left_of_center']

    global prev_progress

    # Read all input parameters
    progress = max(0, params['progress'])
    steps = params['steps']
    speed = params['speed']
    steering_angle = params['steering_angle']
    is_offtrack = params['is_offtrack']

    # Reward - make progress as fast as possible
    prog_per_step = max(0, ((progress / steps) ** 3) * 5)
    prog_diff = max(0, progress - prev_progress)
    reward = prog_per_step + prog_diff

    # Additional reward for faster speed at lesser steering
    if abs(steering_angle) < 10 and speed >= 2.5:
        reward *= 1.3
    elif abs(steering_angle) < 20 and speed >= 1.7:
        reward *= 1.1

    # Start at faster speed as we are starting from Zero
    if steps < 5 and speed >= 2.5:
        reward *= 1.3
    elif steps < 10 and speed >= 1.7:
        reward *= 1.1

    ## Zero reward if off track ##
    if is_offtrack:
        reward = 1e-7

    # Penalize if the agent is too close to the next object
    reward_avoid = 1.0

    if all_wheels_on_track and (0.5 * track_width - distance_from_center) >= 0.05:
        reward_lane = 1.0
    else:
        reward_lane = 1e-3
    # Distance to the next object
    distance_closest_object = objects_distance[next_object_index]
    # Decide if the agent and the next object is on the same lane
    is_same_lane = objects_left_of_center[next_object_index] == is_left_of_center
    
    if is_same_lane:
        if 0.5 <= distance_closest_object < 0.8: 
            reward_avoid *= 0.5
        elif 0.3 <= distance_closest_object < 0.5:
            reward_avoid *= 0.2
        elif distance_closest_object < 0.3:
            reward_avoid = 1e-3 # Likely crashed

    # Calculate reward by putting different weights on 
    # the two aspects above
    reward += 1.0 * reward_lane + 4.0 * reward_avoid

    prev_progress = progress
    return reward
